# -*- coding: utf-8 -*-
"""SleepLab_ML.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17vw3Mg67zS2cff6D7IoI6qACANJgjA7k
"""

import pandas as pd
import numpy as np
import random
import matplotlib.pyplot as plt
import sklearn
import keras
import tensorflow as tf

from keras.models import Sequential
from keras.layers import Dense
from keras.callbacks import EarlyStopping
from keras.callbacks import ModelCheckpoint
from keras.models import load_model

from numpy import ndarray
from sklearn.metrics import confusion_matrix, roc_curve, auc, roc_auc_score, accuracy_score, classification_report

df = pd.read_csv('/content/sample_data/data.csv')

dftarget = df['Sleep Disorder']
target = dftarget.to_numpy()

df = df.drop(columns=['Sleep Disorder'])

data = df.to_numpy()

from sklearn.preprocessing import StandardScaler
s = StandardScaler()
data = s.fit_transform(data)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2)

print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)

def train_mnist(X_train, y_train, X_val, y_val):

    # Define the model
    model = tf.keras.models.Sequential([
        tf.keras.layers.Flatten(),
        tf.keras.layers.Dense(512, activation=tf.nn.relu),
        tf.keras.layers.Dense(10, activation=tf.nn.softmax),
    ])

    # Compile the model
    model.compile(optimizer='adam',
                  loss='sparse_categorical_crossentropy',
                  metrics=['accuracy'])

    # Set up EarlyStopping callback
    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

    # Fit the model with validation data and EarlyStopping callback
    history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[early_stopping])

    # Plot training loss and accuracy
    plot_training_history(history)

    # Evaluate the model on the test set
    val_loss, val_acc = model.evaluate(X_val, y_val)
    print(f"\nValidation Loss: {val_loss}, Validation Accuracy: {val_acc}")

    return history, model

def plot_training_history(history):
    # Plot training loss
    plt.figure(figsize=(10, 5))
    plt.subplot(1, 2, 1)
    plt.plot(history.history['loss'], label='Training Loss')
    plt.plot(history.history['val_loss'], label='Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()

    # Plot training accuracy
    plt.subplot(1, 2, 2)
    plt.plot(history.history['accuracy'], label='Training Accuracy')
    plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
    plt.xlabel('Epochs')
    plt.ylabel('Accuracy')
    plt.legend()

    plt.show()

# Melakukan pelatihan dengan set validasi
history, trained_model = train_mnist(X_train, y_train, X_test, y_test)